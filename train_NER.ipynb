{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9f4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from torchsummary import summary\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertTokenizer, RobertaModel, RobertaTokenizerFast, RobertaTokenizer\n",
    "from transformers import AutoTokenizer, AutoModel, PreTrainedTokenizerFast, AutoConfig, AutoModelForTokenClassification\n",
    "\n",
    "from param import parent_class_mapping\n",
    "from param import CONFIG\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"phobert-base\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tribal-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --trusted-host files.pythonhosted.org --trusted-host pypi.org --trusted-host pypi.python.org transformers \n",
    "# !pip install --upgrade --trusted-host files.pythonhosted.org --trusted-host pypi.org --trusted-host pypi.python.org setuptools_scm \n",
    "# !pip install --upgrade --trusted-host files.pythonhosted.org --trusted-host pypi.org --trusted-host pypi.python.org seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3938f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    MAX_LEN = 100\n",
    "    TRAIN_BATCH_SIZE = 128\n",
    "    VAL_BATCH_SIZE = 128\n",
    "    TEST_BATCH_SIZE = 64\n",
    "    EPOCHS = 5\n",
    "    BASE_MODEL = 'roberta-base'\n",
    "    TRAIN_PATH = 'data/ner_dataset.csv'\n",
    "    MODEL_PATH = 'entity_model.pt'\n",
    "\n",
    "\n",
    "def process_data(df):\n",
    "    enc_tag = preprocessing.LabelEncoder()\n",
    "    df['TAG_enc'] = enc_tag.fit_transform(df['Tag'])\n",
    "    sentences = df.groupby('sentID')['Word'].apply(list).values.tolist()\n",
    "    TAG = df.groupby('sentID')['TAG_enc'].apply(list).values.tolist()\n",
    "    return sentences, TAG, enc_tag\n",
    "\n",
    "device_id = 1\n",
    "torch.cuda.set_device(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e491435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv('data/covid_train_word.csv', index_col=0)\n",
    "dev_df = pd.read_csv('data/covid_dev_word.csv', index_col=0)\n",
    "test_df = pd.read_csv('data/covid_test_word.csv', index_col=0)\n",
    "train_df.head()\n",
    "# train_df[train_df['Tag'] == 'B-PATIENT_ID'].head()\n",
    "\n",
    "\n",
    "# reject_tag = ['B-PATIENT_ID', 'I-PATIENT_ID', 'B-SYMPTOM_AND_DISEASE', 'I-SYMPTOM_AND_DISEASE', 'B-JOB', 'I-JOB']\n",
    "reject_tag = ['B-JOB', 'I-JOB', 'B-TRANSPORTATION', 'I-TRANSPORTATION']\n",
    "\n",
    "all_labels = train_df['Tag'].unique().tolist()\n",
    "train_df.loc[train_df['Tag'].isin(reject_tag), 'Tag'] = 'O'\n",
    "dev_df.loc[dev_df['Tag'].isin(reject_tag), 'Tag'] = 'O'\n",
    "test_df.loc[test_df['Tag'].isin(reject_tag), 'Tag'] = 'O'\n",
    "all_labels = train_df['Tag'].unique().tolist()\n",
    "\n",
    "\n",
    "\n",
    "# df = df.replace({np.nan: 'nan'})\n",
    "# df['sentID'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ab65b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'B-SYMPTOM_AND_DISEASE', 'I-SYMPTOM_AND_DISEASE', 'B-LOCATION', 'I-LOCATION', 'B-DATE', 'B-PATIENT_ID', 'B-AGE', 'B-NAME', 'I-DATE', 'B-GENDER', 'I-GENDER', 'I-NAME', 'I-AGE', 'I-PATIENT_ID']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(all_labels)\n",
    "CLASS_NB = len(all_labels)\n",
    "print(CLASS_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d788fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5027\n"
     ]
    }
   ],
   "source": [
    "sent_ids = train_df.sentID.unique().tolist()\n",
    "print(len(sent_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brazilian-compensation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataset: train 5027, dev 2000, test 3000\n",
      "{'B-AGE': 0, 'B-DATE': 1, 'B-GENDER': 2, 'B-LOCATION': 3, 'B-NAME': 4, 'B-ORGANIZATION': 5, 'B-PATIENT_ID': 6, 'B-SYMPTOM_AND_DISEASE': 7, 'I-AGE': 8, 'I-DATE': 9, 'I-GENDER': 10, 'I-LOCATION': 11, 'I-NAME': 12, 'I-ORGANIZATION': 13, 'I-PATIENT_ID': 14, 'I-SYMPTOM_AND_DISEASE': 15, 'O': 16}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>filename</th>\n",
       "      <th>covid_data</th>\n",
       "      <th>TAG_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Đồng</td>\n",
       "      <td>O</td>\n",
       "      <td>train_word.conll</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>thời</td>\n",
       "      <td>O</td>\n",
       "      <td>train_word.conll</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>train_word.conll</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bệnh</td>\n",
       "      <td>O</td>\n",
       "      <td>train_word.conll</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>viện</td>\n",
       "      <td>O</td>\n",
       "      <td>train_word.conll</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentID  Word Tag          filename  covid_data  TAG_enc\n",
       "0       0  Đồng   O  train_word.conll        True       16\n",
       "1       0  thời   O  train_word.conll        True       16\n",
       "2       0     ,   O  train_word.conll        True       16\n",
       "3       0  bệnh   O  train_word.conll        True       16\n",
       "4       0  viện   O  train_word.conll        True       16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents, train_tag, enc_tag = process_data(train_df)\n",
    "dev_sents, dev_tag, _ = process_data(dev_df)\n",
    "test_sents, test_tag, _ = process_data(test_df)\n",
    "print('number of dataset: train {}, dev {}, test {}'.format(len(train_sents), len(dev_sents), len(test_sents)))\n",
    "\n",
    "train_sents = train_sents + dev_sents\n",
    "train_tag = train_tag + dev_tag\n",
    "\n",
    "\n",
    "tag_nb = len(enc_tag.classes_)\n",
    "tag_mapping = dict(zip(enc_tag.classes_, enc_tag.transform(enc_tag.classes_)))\n",
    "tag_mapping_inv = {value:key for key, value in tag_mapping.items()}\n",
    "print(tag_mapping)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "secondary-express",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7027 3000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sents), len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daed086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tag_encoder_vin.npy', enc_tag.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14abd3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGIN SENTENCE:  Đồng thời , bệnh viện tiếp tục thực hiện các biện pháp phòng chống dịch bệnh COVID - 19 theo hướng dẫn của Bộ Y tế .\n",
      "['<s>', 'Đồng', 'thời', ',', 'bệnh', 'viện', 'tiếp', 'tục', 'thực', 'hiện', 'các', 'biện', 'pháp', 'phòng', 'chống', 'dịch', 'bệnh', 'CO@@', 'VI@@', 'D', '-', '19', 'theo', 'hướng', 'dẫn', 'của', 'Bộ', 'Y', 'tế', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16,  5, 13, 13, 16, 16, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "[['<s>', 16], ['Đồng', 16], ['thời', 16], [',', 16], ['bệnh', 16], ['viện', 16], ['tiếp', 16], ['tục', 16], ['thực', 16], ['hiện', 16], ['các', 16], ['biện', 16], ['pháp', 16], ['phòng', 16], ['chống', 16], ['dịch', 16], ['bệnh', 16], ['CO@@', 16], ['VI@@', 16], ['D', 16], ['-', 16], ['19', 16], ['theo', 16], ['hướng', 16], ['dẫn', 16], ['của', 16], ['Bộ', 5], ['Y', 13], ['tế', 13], ['.', 16], ['</s>', 16], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1], ['<pad>', -1]]\n"
     ]
    }
   ],
   "source": [
    "from dataset import EntityDataset\n",
    "\n",
    "train_dataset = EntityDataset(train_sents, train_tag, tokenizer, tag_mapping, is_train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.TRAIN_BATCH_SIZE, num_workers=8, shuffle=True)\n",
    "val_dataset = EntityDataset(test_sents, test_tag, tokenizer, tag_mapping)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.VAL_BATCH_SIZE, num_workers=8, shuffle=False)\n",
    "\n",
    "# test_dataset = EntityDataset(test_sents, test_tag, tokenizer, tag_mapping)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=Config.VAL_BATCH_SIZE, num_workers=8, shuffle=False)\n",
    "\n",
    "\n",
    "## Test Dataset\n",
    "data = train_dataset[0]\n",
    "ids = list(data['ids'].cpu().numpy().squeeze())\n",
    "seq_len = data['seq_len']\n",
    "\n",
    "print('ORIGIN SENTENCE: ', data['src_sent'])\n",
    "print([tokenizer.decode([id]) for id in ids])\n",
    "# print(tokenizer.decode(ids[:seq_len]))\n",
    "print(data['tar_tag'])\n",
    "\n",
    "print([[tokenizer.decode([id]), int(tag)] for id, tag in zip(ids, data['tar_tag'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a735f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004 0.015 0.003 0.032 0.002 0.007 0.019 0.009 0.    0.015 0.    0.074\n",
      " 0.    0.029 0.    0.014 0.777]\n"
     ]
    }
   ],
   "source": [
    "tag_counter = train_df['TAG_enc'].value_counts().to_dict()\n",
    "class_weight = []\n",
    "\n",
    "for key in range(CLASS_NB):\n",
    "    class_weight.append(tag_counter[key])\n",
    "\n",
    "class_weight = np.array(class_weight)\n",
    "class_weight = class_weight/class_weight.sum()\n",
    "print(np.around(class_weight, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a9d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from transformers.models.roberta.modeling_roberta import *\n",
    "from model import MyRobertaForTokenClassification\n",
    "\n",
    "\n",
    "def parse_data(data, device=torch.device('cuda')):\n",
    "    return (\n",
    "        data['ids'].to(device),\n",
    "        data['mask'].to(device),\n",
    "        data['token_type_ids'].to(device),\n",
    "        data['tar_tag'].to(device), \n",
    "        data['seq_len']\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfb3e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS_WEIGHT:  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0500])\n"
     ]
    }
   ],
   "source": [
    "from torch import functional as F\n",
    "from sklearn import metrics\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "def train_fn(model, train_loader, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in tqdm(train_loader, total=len(train_loader)):\n",
    "        ids, mask, token_type_ids, tag, seq_len = parse_data(data)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = {\n",
    "            \"input_ids\": ids,\n",
    "            \"attention_mask\": mask,\n",
    "            \"labels\": tag,\n",
    "            \"token_type_ids\": token_type_ids\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0].mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scheduler.step(loss)\n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    N = len(train_loader)\n",
    "    return final_loss/N\n",
    "    \n",
    "    \n",
    "def val_fn(model, val_loader, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        all_targets = []\n",
    "        all_outputs = []\n",
    "        f1_score = None\n",
    "        \n",
    "        for data in tqdm(val_loader):\n",
    "            ids, mask, token_type_ids, tags, seq_lens = parse_data(data)\n",
    "            inputs = {\n",
    "                \"input_ids\": ids,\n",
    "                \"attention_mask\": mask,\n",
    "                \"labels\": tags,\n",
    "                \"token_type_ids\": token_type_ids\n",
    "            }\n",
    "            outputs = model(**inputs)\n",
    "            loss, logists = outputs[:2]\n",
    "            \n",
    "            for tag, logist, seq_len in zip(tags, logists, seq_lens):\n",
    "                tag = tag.detach().cpu().numpy()[:seq_len]\n",
    "                label = [tag_mapping_inv[int(t)] for t in tag]\n",
    "\n",
    "                out = logist.detach().cpu().numpy()[:seq_len]\n",
    "                out = np.argmax(out,axis=-1)\n",
    "                pred =  [tag_mapping_inv[int(p)] for p in out]\n",
    "                all_targets.append(label)\n",
    "                all_outputs.append(pred)\n",
    "                \n",
    "        return all_targets, all_outputs\n",
    "\n",
    "# CLASS_WEIGHT = torch.exp(2*torch.Tensor(1-class_weight)).cuda()\n",
    "\n",
    "CLASS_WEIGHT = torch.ones(CLASS_NB)\n",
    "CLASS_WEIGHT[tag_mapping['O']] = 1/20\n",
    "\n",
    "print('CLASS_WEIGHT: ', CLASS_WEIGHT.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continent-analyst",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init robertaFortokenizer Classification model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyRobertaForTokenClassification were not initialized from the model checkpoint at phobert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set loss function to <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "set loss function to <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report, f1_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from model import MyRobertaForTokenClassification\n",
    "\n",
    "device = torch.device('cuda')\n",
    "VLSP_CLASS_NB = 11\n",
    "model = MyRobertaForTokenClassification.from_pretrained(pretrained_model_name_or_path='phobert-base')\n",
    "model.classifier = torch.nn.Linear(in_features=768, out_features=VLSP_CLASS_NB, bias=True)\n",
    "model.num_labels = VLSP_CLASS_NB\n",
    "\n",
    "loss_function = CrossEntropyLoss(weight=torch.zeros(11))\n",
    "model.set_loss_function(loss_function)\n",
    "model.load_state_dict(torch.load('save_model/0.86.pth'))\n",
    "\n",
    "model.classifier = torch.nn.Linear(in_features=768, out_features=CLASS_NB, bias=True)\n",
    "model.num_labels = CLASS_NB\n",
    "\n",
    "# loss_function = CrossEntropyLoss(weight=CLASS_WEIGHT)\n",
    "loss_function = CrossEntropyLoss()\n",
    "model.set_loss_function(loss_function)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "data = next(iter(train_loader))\n",
    "ids, mask, token_type_ids, tag, seq_len = parse_data(data, device)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [{\n",
    "        \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0},\n",
    "    {\n",
    "        \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "optimizer = AdamW(optimizer_parameters, lr=5e-5, eps=1e-8)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.3, patience=3)\n",
    "                      \n",
    "# all_targets, all_outputs = val_fn(model, val_loader, device)       \n",
    "# report = classification_report(all_targets, all_outputs)\n",
    "# print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb144ed4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:19<00:00,  2.83it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  6.13it/s]\n",
      "/opt/conda/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================> Epoch 0\n",
      "Train Loss: 1.1530818353999746\n",
      "F1:  0.7428258396190638\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE       0.00      0.00      0.00       571\n",
      "               DATE       0.96      0.99      0.97      1648\n",
      "             GENDER       0.00      0.00      0.00       473\n",
      "           LOCATION       0.87      0.91      0.89      4629\n",
      "               NAME       0.00      0.00      0.00       551\n",
      "       ORGANIZATION       0.73      0.87      0.79       786\n",
      "         PATIENT_ID       0.56      0.98      0.72      2359\n",
      "SYMPTOM_AND_DISEASE       0.00      0.00      0.00      1144\n",
      "\n",
      "          micro avg       0.76      0.72      0.74     12161\n",
      "          macro avg       0.39      0.47      0.42     12161\n",
      "       weighted avg       0.62      0.72      0.66     12161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE       0.00      0.00      0.00       571\n",
      "               DATE       0.96      0.99      0.97      1648\n",
      "             GENDER       0.00      0.00      0.00       473\n",
      "           LOCATION       0.87      0.91      0.89      4629\n",
      "               NAME       0.00      0.00      0.00       551\n",
      "       ORGANIZATION       0.73      0.87      0.79       786\n",
      "         PATIENT_ID       0.56      0.98      0.72      2359\n",
      "SYMPTOM_AND_DISEASE       0.00      0.00      0.00      1144\n",
      "\n",
      "          micro avg       0.76      0.72      0.74     12161\n",
      "          macro avg       0.39      0.47      0.42     12161\n",
      "       weighted avg       0.62      0.72      0.66     12161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:19<00:00,  2.87it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================> Epoch 1\n",
      "Train Loss: 0.7174153317104687\n",
      "F1:  0.8715854363321133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE       0.86      0.96      0.91       571\n",
      "               DATE       0.97      0.99      0.98      1648\n",
      "             GENDER       0.80      0.88      0.84       473\n",
      "           LOCATION       0.88      0.93      0.90      4629\n",
      "               NAME       0.81      0.91      0.85       551\n",
      "       ORGANIZATION       0.74      0.85      0.79       786\n",
      "         PATIENT_ID       0.96      0.99      0.97      2359\n",
      "SYMPTOM_AND_DISEASE       0.43      0.82      0.57      1144\n",
      "\n",
      "          micro avg       0.82      0.93      0.87     12161\n",
      "          macro avg       0.81      0.91      0.85     12161\n",
      "       weighted avg       0.85      0.93      0.88     12161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:19<00:00,  2.88it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================> Epoch 2\n",
      "Train Loss: 0.6267769445072521\n",
      "F1:  0.9101379724055189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE       0.95      0.95      0.95       571\n",
      "               DATE       0.98      0.99      0.98      1648\n",
      "             GENDER       0.79      0.87      0.83       473\n",
      "           LOCATION       0.90      0.93      0.91      4629\n",
      "               NAME       0.81      0.91      0.86       551\n",
      "       ORGANIZATION       0.81      0.89      0.85       786\n",
      "         PATIENT_ID       0.97      0.99      0.98      2359\n",
      "SYMPTOM_AND_DISEASE       0.68      0.85      0.76      1144\n",
      "\n",
      "          micro avg       0.89      0.94      0.91     12161\n",
      "          macro avg       0.86      0.92      0.89     12161\n",
      "       weighted avg       0.89      0.94      0.91     12161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:19<00:00,  2.86it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  6.22it/s]\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================> Epoch 3\n",
      "Train Loss: 0.6040089352564378\n",
      "F1:  0.7751094112022361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:19<00:00,  2.85it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  6.29it/s]\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================> Epoch 4\n",
      "Train Loss: 0.5725936060602015\n",
      "F1:  0.7220042854788198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:18<00:00,  2.91it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  6.21it/s]\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================> Epoch 5\n",
      "Train Loss: 0.549939469315789\n",
      "F1:  0.6607049608355092\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE       0.93      0.96      0.95       571\n",
      "               DATE       0.97      0.99      0.98      1648\n",
      "             GENDER       0.26      0.96      0.41       473\n",
      "           LOCATION       0.69      0.72      0.70      4629\n",
      "               NAME       0.69      0.94      0.79       551\n",
      "       ORGANIZATION       0.71      0.75      0.73       786\n",
      "         PATIENT_ID       0.94      0.99      0.96      2359\n",
      "SYMPTOM_AND_DISEASE       0.13      0.63      0.21      1144\n",
      "\n",
      "          micro avg       0.55      0.83      0.66     12161\n",
      "          macro avg       0.67      0.87      0.72     12161\n",
      "       weighted avg       0.72      0.83      0.75     12161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:18<00:00,  2.90it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  6.12it/s]\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================> Epoch 6\n",
      "Train Loss: 0.5219078855081039\n",
      "F1:  0.7215891696996497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:18<00:00,  2.91it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  6.14it/s]\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================> Epoch 7\n",
      "Train Loss: 0.46780680851502854\n",
      "F1:  0.6902088772845953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 19/55 [00:12<00:23,  1.55it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dae16af424aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_F1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mall_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-1b5827b710ce>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, train_loader, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         }\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/home/ngoccm1/Desktop/TrungNT98/NER-covid-training/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         )\n\u001b[0;32m--> 847\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    848\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    521\u001b[0m                 )\n\u001b[1;32m    522\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    524\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;31m# inspect.signature exist since python 3.5 and is a python method -> no problem with backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mnum_args_in_forward_chunk_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_args_in_forward_chunk_fn\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3091\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3092\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3093\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2841\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   2843\u001b[0m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2219\u001b[0m         \u001b[0;31m# In this case we skip the first parameter of the underlying\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m         \u001b[0;31m# function (usually `self` or `cls`).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m         sig = _signature_from_callable(\n\u001b[0m\u001b[1;32m   2222\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m             \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2293\u001b[0m                                         skip_bound_arg=skip_bound_arg)\n\u001b[1;32m   2294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_POSITIONAL_ONLY\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mposonly_left\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0m\u001b[1;32m   2157\u001b[0m                                     kind=kind))\n\u001b[1;32m   2158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mposonly_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2478\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2479\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2480\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'value {kind!r} is not a valid Parameter.kind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \"\"\"\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# simple value lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;31m# otherwise, functional API: we're creating a new Enum type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/enum.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \"\"\"\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;31m# all enum instances are actually created during class construction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# without calling this method; this method is called by the metaclass'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report, f1_score\n",
    "\n",
    "os.makedirs('save_model', exist_ok=True)\n",
    "best_F1 = -np.inf\n",
    "for epoch in range(40):\n",
    "    loss =  train_fn(model, train_loader, optimizer, device, scheduler)\n",
    "    all_targets, all_outputs = val_fn(model, val_loader, device)\n",
    "    \n",
    "    F1 = f1_score(all_targets, all_outputs)\n",
    "    report = classification_report(all_targets, all_outputs)\n",
    "    \n",
    "    print('======================> Epoch {}'.format(epoch))\n",
    "    print(\"Train Loss: {}\".format(loss))\n",
    "    print('F1: ', F1)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(report)\n",
    "        \n",
    "    \n",
    "    if F1 > best_F1:\n",
    "        torch.save(model.state_dict(), 'save_model/{:.4f}.pth'.format(F1))\n",
    "        best_F1 = F1\n",
    "        print(report)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_B_O_tag(label):\n",
    "    if label != 'O':\n",
    "        return label[2:]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b2761",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_model\n",
    "entity_model = model\n",
    "entity_model.eval()\n",
    "all_ids = []\n",
    "all_tar_tag = []\n",
    "all_out_tag = []\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "\n",
    "for batch in val_loader:\n",
    "    id_batch, mask_batch, token_batch, tag_batch, seq_len_batch = parse_data(data)\n",
    "#     print(tokenizer.convert_ids_to_tokens(list(id_batch[0].cpu().numpy())))\n",
    "    out_tag_batch = entity_model(id_batch, mask_batch, token_batch)\n",
    "    \n",
    "    id_batch = id_batch.cpu().numpy()\n",
    "    out_tag_batch = torch.argmax(out_tag_batch, 2).cpu().numpy()\n",
    "    tag_batch = tag_batch.cpu().numpy()\n",
    "    BATCH_SIZE = len(id_batch)\n",
    "    \n",
    "    for i in range(BATCH_SIZE):\n",
    "        l = seq_len_batch[i] # sequence length\n",
    "        ids = id_batch[i][:l]\n",
    "        tag = tag_batch[i][:l]\n",
    "        out_tag = out_tag_batch[i][:l]\n",
    "\n",
    "        all_ids.append(list(ids))\n",
    "        all_tar_tag.append(list(tag))\n",
    "        all_out_tag.append(list(out_tag))\n",
    "        \n",
    "        if (tag-out_tag).sum() != 0:\n",
    "            print(\"=\"*100)\n",
    "            print(\"Output tag \", enc_tag.inverse_transform(out_tag))\n",
    "            print(\"Target tag \", enc_tag.inverse_transform(tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-appearance",
   "metadata": {},
   "source": [
    "## Test model with raw sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def sentence_to_input(sent, device=torch.device('cuda'), max_len=100):\n",
    "        \"\"\"\n",
    "        Convert text input to list of token_id with additinal info\n",
    "        Input: Sentence in string format\n",
    "        Output: token_ids, mask, token_type_ids, offset_map, seq_len\n",
    "        \"\"\"\n",
    "        input = tokenizer.encode_plus(sent, add_special_tokens=True, max_length=max_len, padding='max_length')\n",
    "        token_ids = input['input_ids']\n",
    "        mask = input['attention_mask']\n",
    "#         offset_map = input['offset_mapping']\n",
    "            \n",
    "        token_type_ids = [0]*len(token_ids)\n",
    "        token_ids = torch.tensor(token_ids, dtype=torch.long)\n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(token_type_ids, dtype=torch.long)\n",
    "        real_seq_len = int(mask.sum())\n",
    "\n",
    "        token_ids = token_ids.unsqueeze(dim=0).to(device)\n",
    "        mask = mask.unsqueeze(dim=0).to(device)\n",
    "        token_type_ids = token_type_ids.unsqueeze(dim=0).to(device)\n",
    "        \n",
    "        return token_ids, mask, token_type_ids, real_seq_len\n",
    "\n",
    "def decode_output(output, offset, seq_len):\n",
    "    output = output.squeeze()[:seq_len]\n",
    "    offset = offset[:seq_len]\n",
    "    filted_output = [output[1]]\n",
    "\n",
    "    for i in range(1, seq_len-1):\n",
    "        pre_word_ind = offset[i-1]\n",
    "        cur_word_ind = offset[i]\n",
    "        if cur_word_ind[0] != pre_word_ind[1]:\n",
    "            filted_output.append(output[i])\n",
    "    return filted_output\n",
    "\n",
    "device = torch.device('cuda')\n",
    "VLSP_CLASS_NB = 11\n",
    "model = MyRobertaForTokenClassification.from_pretrained(pretrained_model_name_or_path='phobert-base')\n",
    "model.classifier = torch.nn.Linear(in_features=768, out_features=VLSP_CLASS_NB, bias=True)\n",
    "model.num_labels = VLSP_CLASS_NB\n",
    "loss_function = CrossEntropyLoss(weight=CLASS_WEIGHT)\n",
    "\n",
    "model.set_loss_function(loss_function)\n",
    "model.load_state_dict(torch.load('../Team3-BTL NLP/source-code/save_model/0.86.pth'))\n",
    "\n",
    "model.classifier = torch.nn.Linear(in_features=768, out_features=CLASS_NB, bias=True)\n",
    "model.num_labels = VLSP_CLASS_NB\n",
    "print('CLASS WEIGHT: ', CLASS_WEIGHT.shape, CLASS_WEIGHT)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95a0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5104623",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Tôi tên là Nguyễn Thành Trung, người ở xã Hòa Bình - tỉnh Thái Bình. Tôi đang làm giám đốc tại công ty Dash Tech'\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load('tag_encoder_vin.npy',  allow_pickle=True)\n",
    "\n",
    "tag_mapping = dict(zip(enc_tag.classes_, enc_tag.transform(enc_tag.classes_)))\n",
    "tag_mapping_inv = {value:key for key, value in tag_mapping.items()}\n",
    "\n",
    "token_ids, mask, token_type_ids, real_seq_len = sentence_to_input(sent)\n",
    "\n",
    "inputs = {\n",
    "    \"input_ids\": token_ids.to(device),\n",
    "    \"attention_mask\": mask.to(device),\n",
    "    \"token_type_ids\": token_type_ids.to(device)\n",
    "}\n",
    "outputs = model(**inputs).logits\n",
    "out = outputs[0].detach().cpu().numpy()[:real_seq_len]\n",
    "out = np.argmax(out,axis=-1)\n",
    "tags =  [tag_mapping_inv[int(p)] for p in out]\n",
    "token_ids = list(token_ids[:real_seq_len].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_output(token_ids, tags):\n",
    "    result = []\n",
    "    cur_sent = []\n",
    "    cur_tag = []\n",
    "    for token, tag in zip(token_ids, tags):\n",
    "        if tag == 'O':\n",
    "            continue\n",
    "        if 'B-' in tag:\n",
    "            if cur_sent:\n",
    "                result.append([tokenizer.decode(cur_sent), cur_tag[0].split('-')[1]])\n",
    "            cur_sent = [token]\n",
    "            cur_tag = [tag]\n",
    "\n",
    "        if 'I-' in tag:\n",
    "            cur_sent.append(token)\n",
    "            cur_tag.append(tag)\n",
    "\n",
    "    if cur_sent:\n",
    "        result.append([tokenizer.decode(cur_sent), cur_tag[0].split('-')[1]])\n",
    "    return str(result)\n",
    "\n",
    "result = decode_output(token_ids, tags)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254053fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ''\n",
    "for token, tag in zip(token_ids, tags):\n",
    "    output += ' {} <{}> '.format(tokenizer.decode([token]), tag)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28f656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7926477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
